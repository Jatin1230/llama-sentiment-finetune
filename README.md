# ğŸ¦™ LLaMA Sentiment Fine-Tuning (PyTorch + LoRA)

This project fine-tunes a LLaMA-based language model for sentiment analysis using **LoRA (Low-Rank Adaptation)** with **PyTorch**. It demonstrates how to adapt large language models efficiently on custom classification tasks using parameter-efficient fine-tuning.

---

## ğŸ“Œ Project Highlights

- âœ… Fine-tuned Metaâ€™s LLaMA model for binary sentiment classification (positive/negative)
- âœ… Used HuggingFaceâ€™s `transformers`, `datasets`, and `peft` libraries
- âœ… Integrated **LoRA** to significantly reduce GPU memory and training time
- âœ… Trained on a lightweight IMDb-style custom dataset
- âœ… Supports inference with LoRA adapters

---

## ğŸ› ï¸ Tech Stack

- **Model:** LLaMA-2 7B (HuggingFace format)
- **Framework:** PyTorch
- **Fine-Tuning Method:** LoRA via PEFT
- **Tokenizer:** LLaMA tokenizer (sentencepiece)
- **Dataset:** IMDb-like dataset for sentiment classification
- **Training Strategy:** Gradient checkpointing + mixed precision

---

## ğŸ§¾ Directory Structure

llama-sentiment-finetune/
â”‚
â”œâ”€â”€ data/
  â””â”€â”€ train.json # Processed training & validation data
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ llama/ # Base LLaMA weights (HF format)
â”‚
â”œâ”€â”€ adapters/ # Trained LoRA adapters after fine-tuning
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ finetune.py # Fine-tuning script
â”‚ â””â”€â”€ prepare_dataset.py # fir preparing dataset
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md
